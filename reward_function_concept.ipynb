{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_reward(evaluation, penalty=0.5):\n",
    "    \"\"\"\n",
    "    Calculates the reward for the weak LLM based on evaluation metrics and applies a penalty if it loses.\n",
    "    \n",
    "    Args:\n",
    "        evaluation (dict): Evaluation scores and preference from judge LLM.\n",
    "        penalty (float): The penalty to apply if the weak LLM loses the debate.\n",
    "    \n",
    "    Returns:\n",
    "        float: The calculated reward for the weak LLM.\n",
    "    \"\"\"\n",
    "    # Weights for different metrics\n",
    "    alpha, beta, gamma, delta, epsilon = 0.2, 0.2, 0.2, 0.2, 0.2  # Adjust based on priorities\n",
    "    \n",
    "    # Scores for Agent A (weak LLM)\n",
    "    relevance_A = evaluation.get(\"relevance_A\", 0)\n",
    "    persuasiveness_A = evaluation.get(\"persuasiveness_A\", 0)\n",
    "    coherence_A = evaluation.get(\"coherence_A\", 0)\n",
    "    creativity_A = evaluation.get(\"creativity_A\", 0)\n",
    "    ethical_alignment_A = evaluation.get(\"ethical_alignment_A\", 0)\n",
    "    \n",
    "    # Aggregate reward for weak LLM (Agent A)\n",
    "    reward_A = (\n",
    "        alpha * relevance_A +\n",
    "        beta * persuasiveness_A +\n",
    "        gamma * coherence_A +\n",
    "        delta * creativity_A +\n",
    "        epsilon * ethical_alignment_A\n",
    "    )\n",
    "    \n",
    "    # Determine if Agent A (weak LLM) won\n",
    "    if evaluation.get(\"preference\") == \"Agent A\":\n",
    "        # Add a bonus for winning\n",
    "        reward_A += 1.0  # Winning bonus\n",
    "    else:\n",
    "        # Apply a penalty for losing\n",
    "        reward_A -= penalty  # Losing penalty\n",
    "    \n",
    "    # Ensure reward is non-negative\n",
    "    reward_A = max(reward_A, 0.0)\n",
    "    \n",
    "    return reward_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def judge_llm_evaluate(topic, response, opponent_response):\n",
    "    \"\"\"\n",
    "    Uses a well-trained LLM to evaluate debate responses.\n",
    "    \n",
    "    Args:\n",
    "        topic (str): The debate topic.\n",
    "        response (str): The weak LLM's response.\n",
    "        opponent_response (str): The opponent's response.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing scores for metrics and the preferred response.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Debate Topic: {topic}\n",
    "    \n",
    "    Agent A's Response: {response}\n",
    "    Agent B's Response: {opponent_response}\n",
    "    \n",
    "    Evaluate the responses based on:\n",
    "    - Relevance (0-1)\n",
    "    - Persuasiveness (0-1)\n",
    "    - Coherence (0-1)\n",
    "    - Creativity (0-1)\n",
    "    - Ethical Alignment (0-1)\n",
    "    \n",
    "    Additionally, provide a preference:\n",
    "    - Which response (Agent A or Agent B) performed better overall?\n",
    "    \n",
    "    Output the results in JSON format:\n",
    "    {{\n",
    "        \"relevance_A\": <float>,\n",
    "        \"persuasiveness_A\": <float>,\n",
    "        \"coherence_A\": <float>,\n",
    "        \"creativity_A\": <float>,\n",
    "        \"ethical_alignment_A\": <float>,\n",
    "        \"relevance_B\": <float>,\n",
    "        \"persuasiveness_B\": <float>,\n",
    "        \"coherence_B\": <float>,\n",
    "        \"creativity_B\": <float>,\n",
    "        \"ethical_alignment_B\": <float>,\n",
    "        \"preference\": \"Agent A\" or \"Agent B\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the OpenAI API or any other LLM to evaluate\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are an expert debate evaluator.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        evaluation = response['choices'][0]['message']['content']\n",
    "        return eval(evaluation)  # Convert JSON string to dictionary\n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {e}\")\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
