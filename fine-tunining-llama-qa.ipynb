{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-11-11T22:31:08.617705Z","iopub.status.busy":"2024-11-11T22:31:08.617322Z","iopub.status.idle":"2024-11-11T22:31:09.076664Z","shell.execute_reply":"2024-11-11T22:31:09.075558Z","shell.execute_reply.started":"2024-11-11T22:31:08.617659Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/model.safetensors.index.json\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/config.json\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/model-00001-of-00002.safetensors\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/model-00002-of-00002.safetensors\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/README.md\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/USE_POLICY.md\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/tokenizer.json\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/tokenizer_config.json\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/LICENSE.txt\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/special_tokens_map.json\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/.gitattributes\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/generation_config.json\n","/kaggle/input/llama-3.2/pytorch/3b/1/consolidated.00.pth\n","/kaggle/input/llama-3.2/pytorch/3b/1/params.json\n","/kaggle/input/llama-3.2/pytorch/3b/1/tokenizer.model\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# **ON QA TASK**"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:31:09.080350Z","iopub.status.busy":"2024-11-11T22:31:09.078093Z","iopub.status.idle":"2024-11-11T22:32:30.541112Z","shell.execute_reply":"2024-11-11T22:32:30.539885Z","shell.execute_reply.started":"2024-11-11T22:31:09.080313Z"},"trusted":true},"outputs":[],"source":["%%capture\n","%pip install -U transformers \n","%pip install -U datasets \n","%pip install -U accelerate \n","%pip install -U peft \n","%pip install -U trl \n","%pip install -U bitsandbytes \n","%pip install -U wandb"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:32:30.731545Z","iopub.status.busy":"2024-11-11T22:32:30.731093Z","iopub.status.idle":"2024-11-11T22:32:38.754587Z","shell.execute_reply":"2024-11-11T22:32:38.753616Z","shell.execute_reply.started":"2024-11-11T22:32:30.731494Z"},"trusted":true},"outputs":[],"source":["from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    pipeline,\n","    logging,\n",")\n","from peft import (\n","    LoraConfig,\n","    PeftModel,\n","    prepare_model_for_kbit_training,\n","    get_peft_model,\n",")\n","import os, torch, wandb\n","from datasets import load_dataset\n","from trl import SFTTrainer, setup_chat_format"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:32:42.322569Z","iopub.status.busy":"2024-11-11T22:32:42.321835Z","iopub.status.idle":"2024-11-11T22:32:46.392594Z","shell.execute_reply":"2024-11-11T22:32:46.391770Z","shell.execute_reply.started":"2024-11-11T22:32:42.322519Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: fineGrained).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrakibulislamprince10\u001b[0m (\u001b[33mrakibulislamprince10-purdue-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.18.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241111_223244-y2p6bvbg</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20Llama%203.2%203B%20on%20Medical%20Dataset/runs/y2p6bvbg' target=\"_blank\">exalted-serenity-2</a></strong> to <a href='https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20Llama%203.2%203B%20on%20Medical%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20Llama%203.2%203B%20on%20Medical%20Dataset' target=\"_blank\">https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20Llama%203.2%203B%20on%20Medical%20Dataset</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20Llama%203.2%203B%20on%20Medical%20Dataset/runs/y2p6bvbg' target=\"_blank\">https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20Llama%203.2%203B%20on%20Medical%20Dataset/runs/y2p6bvbg</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import login\n","from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","\n","hf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n","\n","login(token = hf_token)\n","\n","wb_token = user_secrets.get_secret(\"wandb\")\n","\n","wandb.login(key=wb_token)\n","run = wandb.init(\n","    project='Fine-tune Llama 3.2 3B on Medical Dataset', \n","    job_type=\"training\", \n","    anonymous=\"allow\"\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:32:50.774706Z","iopub.status.busy":"2024-11-11T22:32:50.774273Z","iopub.status.idle":"2024-11-11T22:32:50.781487Z","shell.execute_reply":"2024-11-11T22:32:50.780614Z","shell.execute_reply.started":"2024-11-11T22:32:50.774664Z"},"trusted":true},"outputs":[],"source":["base_model = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\n","dataset_name = \"ruslanmv/ai-medical-chatbot\"\n","new_model = \"llama-3.2-3b-instruct-doctor\""]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:32:53.680743Z","iopub.status.busy":"2024-11-11T22:32:53.680302Z","iopub.status.idle":"2024-11-11T22:32:53.686269Z","shell.execute_reply":"2024-11-11T22:32:53.685294Z","shell.execute_reply.started":"2024-11-11T22:32:53.680703Z"},"trusted":true},"outputs":[],"source":["torch_dtype = torch.float16\n","attn_implementation = \"eager\""]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:32:59.697085Z","iopub.status.busy":"2024-11-11T22:32:59.696221Z","iopub.status.idle":"2024-11-11T22:33:39.273220Z","shell.execute_reply":"2024-11-11T22:33:39.272344Z","shell.execute_reply.started":"2024-11-11T22:32:59.697042Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09fb5a657af640268893a88c5edb0dc8","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# QLoRA config\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch_dtype,\n","    bnb_4bit_use_double_quant=True,\n",")\n","\n","# Load model\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    attn_implementation=attn_implementation\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:34:08.297835Z","iopub.status.busy":"2024-11-11T22:34:08.296981Z","iopub.status.idle":"2024-11-11T22:34:09.675815Z","shell.execute_reply":"2024-11-11T22:34:09.674645Z","shell.execute_reply.started":"2024-11-11T22:34:08.297793Z"},"trusted":true},"outputs":[{"ename":"ValueError","evalue":"Chat template is already added to the tokenizer. If you want to overwrite it, please set it to None","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load tokenizer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(base_model)\n\u001b[0;32m----> 3\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43msetup_chat_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/models/utils.py:101\u001b[0m, in \u001b[0;36msetup_chat_format\u001b[0;34m(model, tokenizer, format, resize_to_multiple_of)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# check if model already had a chat template\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mchat_template \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChat template is already added to the tokenizer. If you want to overwrite it, please set it to None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m     )\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# check if format available and retrieve\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m FORMAT_MAPPING:\n","\u001b[0;31mValueError\u001b[0m: Chat template is already added to the tokenizer. If you want to overwrite it, please set it to None"]}],"source":["# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(base_model)\n","model, tokenizer = setup_chat_format(model, tokenizer)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:34:38.287763Z","iopub.status.busy":"2024-11-11T22:34:38.287364Z","iopub.status.idle":"2024-11-11T22:34:38.840072Z","shell.execute_reply":"2024-11-11T22:34:38.839191Z","shell.execute_reply.started":"2024-11-11T22:34:38.287723Z"},"trusted":true},"outputs":[],"source":["# LoRA config\n","peft_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",")\n","model = get_peft_model(model, peft_config)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:34:42.280250Z","iopub.status.busy":"2024-11-11T22:34:42.279857Z","iopub.status.idle":"2024-11-11T22:34:49.675990Z","shell.execute_reply":"2024-11-11T22:34:49.674919Z","shell.execute_reply.started":"2024-11-11T22:34:42.280210Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d963393d363a4f2faf1620a8e008838a","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/863 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90371d068c454894a5fe4ed4228a1e40","version_major":2,"version_minor":0},"text/plain":["dialogues.parquet:   0%|          | 0.00/142M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c362c17d6d3540d18e89c1f826b7e0ca","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/256916 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a50948f58ffc4ae49b677ae9dc2751d6","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"text/plain":["'<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nFell on sidewalk face first about 8 hrs ago. Swollen, cut lip bruised and cut knee, and hurt pride initially. Now have muscle and shoulder pain, stiff jaw(think this is from the really swollen lip),pain in wrist, and headache. I assume this is all normal but are there specific things I should look for or will I just be in pain for a while given the hard fall?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nHello and welcome to HCM,The injuries caused on various body parts have to be managed.The cut and swollen lip has to be managed by sterile dressing.The body pains, pain on injured site and jaw pain should be managed by pain killer and muscle relaxant.I suggest you to consult your primary healthcare provider for clinical assessment.In case there is evidence of infection in any of the injured sites, a course of antibiotics may have to be started to control the infection.Thanks and take careDr Shailja P Wahal<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["#Importing the dataset\n","dataset = load_dataset(dataset_name, split=\"all\")\n","dataset = dataset.shuffle(seed=65).select(range(1000)) # Only use 1000 samples for quick demo\n","\n","def format_chat_template(row):\n","    row_json = [{\"role\": \"user\", \"content\": row[\"Patient\"]},\n","               {\"role\": \"assistant\", \"content\": row[\"Doctor\"]}]\n","    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n","    return row\n","\n","dataset = dataset.map(\n","    format_chat_template,\n","    num_proc=4,\n",")\n","\n","dataset['text'][3]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:34:57.746350Z","iopub.status.busy":"2024-11-11T22:34:57.745945Z","iopub.status.idle":"2024-11-11T22:34:57.763275Z","shell.execute_reply":"2024-11-11T22:34:57.762519Z","shell.execute_reply.started":"2024-11-11T22:34:57.746309Z"},"trusted":true},"outputs":[],"source":["dataset = dataset.train_test_split(test_size=0.1)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:35:00.522552Z","iopub.status.busy":"2024-11-11T22:35:00.522121Z","iopub.status.idle":"2024-11-11T22:35:00.556247Z","shell.execute_reply":"2024-11-11T22:35:00.555161Z","shell.execute_reply.started":"2024-11-11T22:35:00.522514Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["training_arguments = TrainingArguments(\n","    output_dir=new_model,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    gradient_accumulation_steps=2,\n","    optim=\"paged_adamw_32bit\",\n","    num_train_epochs=1,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=0.2,\n","    logging_steps=1,\n","    warmup_steps=10,\n","    logging_strategy=\"steps\",\n","    learning_rate=2e-4,\n","    fp16=False,\n","    bf16=False,\n","    group_by_length=True,\n","    report_to=\"wandb\"\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:35:05.320842Z","iopub.status.busy":"2024-11-11T22:35:05.320422Z","iopub.status.idle":"2024-11-11T22:35:06.788268Z","shell.execute_reply":"2024-11-11T22:35:06.787454Z","shell.execute_reply.started":"2024-11-11T22:35:05.320804Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n","\n","Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n","  warnings.warn(message, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92a2fa71d60d4341bf1ee3083fb5f46f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/900 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da98d04330c84380a45ef4094d055e28","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/100 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    peft_config=peft_config,\n","    max_seq_length=512,\n","    dataset_text_field=\"text\",\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n","    packing= False,\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:36:07.637628Z","iopub.status.busy":"2024-11-11T22:36:07.636448Z","iopub.status.idle":"2024-11-11T22:50:25.233043Z","shell.execute_reply":"2024-11-11T22:50:25.232241Z","shell.execute_reply.started":"2024-11-11T22:36:07.637572Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [450/450 14:13, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>90</td>\n","      <td>2.508300</td>\n","      <td>2.688563</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>2.515100</td>\n","      <td>2.645705</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>2.607900</td>\n","      <td>2.624050</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>3.084100</td>\n","      <td>2.604542</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>2.843300</td>\n","      <td>2.594652</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n","Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"data":{"text/plain":["TrainOutput(global_step=450, training_loss=2.6913100565804378, metrics={'train_runtime': 856.5873, 'train_samples_per_second': 1.051, 'train_steps_per_second': 0.525, 'total_flos': 3548430429751296.0, 'train_loss': 2.6913100565804378, 'epoch': 1.0})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.pad_token = tokenizer.eos_token\n","trainer.train()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:52:09.027939Z","iopub.status.busy":"2024-11-11T22:52:09.027522Z","iopub.status.idle":"2024-11-11T22:52:12.111848Z","shell.execute_reply":"2024-11-11T22:52:12.110959Z","shell.execute_reply.started":"2024-11-11T22:52:09.027901Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18c71afbbbe847d0b103a9504b145a2a","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.015 MB of 0.015 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <style>\n","        .wandb-row {\n","            display: flex;\n","            flex-direction: row;\n","            flex-wrap: wrap;\n","            justify-content: flex-start;\n","            width: 100%;\n","        }\n","        .wandb-col {\n","            display: flex;\n","            flex-direction: column;\n","            flex-basis: 100%;\n","            flex: 1;\n","            padding: 10px;\n","        }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñÑ‚ñà‚ñÉ‚ñÜ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñÜ‚ñÅ‚ñà‚ñÉ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñÜ‚ñÅ‚ñà‚ñÉ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÜ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ</td></tr><tr><td>train/learning_rate</td><td>‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.59465</td></tr><tr><td>eval/runtime</td><td>36.2803</td></tr><tr><td>eval/samples_per_second</td><td>2.756</td></tr><tr><td>eval/steps_per_second</td><td>2.756</td></tr><tr><td>total_flos</td><td>3548430429751296.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>450</td></tr><tr><td>train/grad_norm</td><td>2.32514</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>2.8433</td></tr><tr><td>train_loss</td><td>2.69131</td></tr><tr><td>train_runtime</td><td>856.5873</td></tr><tr><td>train_samples_per_second</td><td>1.051</td></tr><tr><td>train_steps_per_second</td><td>0.525</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">exalted-serenity-2</strong> at: <a href='https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20Llama%203.2%203B%20on%20Medical%20Dataset/runs/y2p6bvbg' target=\"_blank\">https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20Llama%203.2%203B%20on%20Medical%20Dataset/runs/y2p6bvbg</a><br/> View project at: <a href='https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20Llama%203.2%203B%20on%20Medical%20Dataset' target=\"_blank\">https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20Llama%203.2%203B%20on%20Medical%20Dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241111_223244-y2p6bvbg/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()\n","model.config.use_cache = True"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:52:54.019119Z","iopub.status.busy":"2024-11-11T22:52:54.018725Z","iopub.status.idle":"2024-11-11T22:53:09.920954Z","shell.execute_reply":"2024-11-11T22:53:09.919897Z","shell.execute_reply.started":"2024-11-11T22:52:54.019082Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Hi,Thanks for asking. Acne is caused by the oil produced by the glands at the base of the hair follicles. This oil is rich in sebum. When it is mixed with dead skin cells and bacteria, it causes the acne. It is not a disease but a problem. It is not curable but it can be controlled. For the treatment, you can use the following: 1. Wash your face with a mild soap. 2. Use a toner. 3. Apply a face cream or gel. 4. Use a sunscreen. 5. Avoid eating too many gre\n"]}],"source":["messages = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": \"Hello doctor, I have bad acne. How do I get rid of it?\"\n","    }\n","]\n","\n","prompt = tokenizer.apply_chat_template(messages, tokenize=False, \n","                                       add_generation_prompt=True)\n","\n","inputs = tokenizer(prompt, return_tensors='pt', padding=True, \n","                   truncation=True).to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_length=150, \n","                         num_return_sequences=1)\n","\n","text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(text.split(\"assistant\")[1])"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5338273,"sourceId":8870083,"sourceType":"datasetVersion"},{"modelId":121027,"modelInstanceId":97843,"sourceId":116428,"sourceType":"modelInstanceVersion"},{"modelId":121027,"modelInstanceId":100936,"sourceId":120005,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
