{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-11-11T21:26:29.390999Z","iopub.status.busy":"2024-11-11T21:26:29.390476Z","iopub.status.idle":"2024-11-11T21:26:29.798317Z","shell.execute_reply":"2024-11-11T21:26:29.797336Z","shell.execute_reply.started":"2024-11-11T21:26:29.390951Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/llama-3.2/transformers/3b-instruct/1/model.safetensors.index.json\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/config.json\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/model-00001-of-00002.safetensors\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/model-00002-of-00002.safetensors\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/README.md\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/USE_POLICY.md\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/tokenizer.json\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/tokenizer_config.json\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/LICENSE.txt\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/special_tokens_map.json\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/.gitattributes\n","/kaggle/input/llama-3.2/transformers/3b-instruct/1/generation_config.json\n","/kaggle/input/llama-3.2/pytorch/3b/1/consolidated.00.pth\n","/kaggle/input/llama-3.2/pytorch/3b/1/params.json\n","/kaggle/input/llama-3.2/pytorch/3b/1/tokenizer.model\n","/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:26:29.800426Z","iopub.status.busy":"2024-11-11T21:26:29.799644Z","iopub.status.idle":"2024-11-11T21:26:41.924145Z","shell.execute_reply":"2024-11-11T21:26:41.922979Z","shell.execute_reply.started":"2024-11-11T21:26:29.800371Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.2)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -U transformers accelerate"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:26:41.927966Z","iopub.status.busy":"2024-11-11T21:26:41.927501Z","iopub.status.idle":"2024-11-11T21:26:55.989202Z","shell.execute_reply":"2024-11-11T21:26:55.988384Z","shell.execute_reply.started":"2024-11-11T21:26:41.927927Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb1d2b84b859444b9efe24fd187a4196","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Checking the working of the base llama\n","from transformers import AutoTokenizer,AutoModelForCausalLM,pipeline\n","import torch\n","\n","base_model = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(base_model)\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","        base_model,\n","        return_dict=True,\n","        low_cpu_mem_usage=True,\n","        torch_dtype=torch.float16,\n","        device_map=\"auto\",\n","        trust_remote_code=True,\n",")\n","pipe = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\",\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:26:55.991856Z","iopub.status.busy":"2024-11-11T21:26:55.990656Z","iopub.status.idle":"2024-11-11T21:27:02.596073Z","shell.execute_reply":"2024-11-11T21:27:02.595032Z","shell.execute_reply.started":"2024-11-11T21:26:55.991804Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n","\n","What is the tallest building in the world?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n","\n","The tallest building in the world is the Burj Khalifa, located in Dubai, United Arab Emirates. It stands at a height of 828 meters (2,722 feet) and has 163 floors. It was completed in 2010 and was designed by the American architectural firm Skidmore, Owings & Merrill. The Burj Khalifa holds several world records, including the highest occupied floor, highest outdoor observation deck, elevator with the longest travel distance, and the tallest freestanding structure in the world.\n","\n","Would you like to know more about the Burj Khalifa or is there\n"]}],"source":["messages = [{\"role\": \"user\", \"content\": \"What is the tallest building in the world?\"}]\n","\n","prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","outputs = pipe(prompt, max_new_tokens=120, do_sample=True)\n","print(outputs[0][\"generated_text\"])"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:27:02.597560Z","iopub.status.busy":"2024-11-11T21:27:02.597228Z","iopub.status.idle":"2024-11-11T21:28:00.662655Z","shell.execute_reply":"2024-11-11T21:28:00.661294Z","shell.execute_reply.started":"2024-11-11T21:27:02.597525Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]}],"source":["%%capture\n","%pip install -U bitsandbytes\n","%pip install -U transformers\n","%pip install -U accelerate\n","%pip install -U peft\n","%pip install -U trl"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:12:14.311850Z","iopub.status.busy":"2024-11-11T22:12:14.310864Z","iopub.status.idle":"2024-11-11T22:12:27.064079Z","shell.execute_reply":"2024-11-11T22:12:27.062839Z","shell.execute_reply.started":"2024-11-11T22:12:14.311803Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\n","Collecting datasets\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: datasets\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 3.0.1\n","    Uninstalling datasets-3.0.1:\n","      Successfully uninstalled datasets-3.0.1\n","Successfully installed datasets-3.1.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -U datasets "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:28:00.664625Z","iopub.status.busy":"2024-11-11T21:28:00.664290Z","iopub.status.idle":"2024-11-11T21:28:05.423764Z","shell.execute_reply":"2024-11-11T21:28:05.422715Z","shell.execute_reply.started":"2024-11-11T21:28:00.664589Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrakibulislamprince10\u001b[0m (\u001b[33mrakibulislamprince10-purdue-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a9937d2c4c14261b50366866142e1e3","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111301828889029, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241111_212802-534ugfw0</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20llama-3.1-8b-it%20on%20Sentiment%20Analysis%20Dataset/runs/534ugfw0' target=\"_blank\">light-pine-2</a></strong> to <a href='https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20llama-3.1-8b-it%20on%20Sentiment%20Analysis%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20llama-3.1-8b-it%20on%20Sentiment%20Analysis%20Dataset' target=\"_blank\">https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20llama-3.1-8b-it%20on%20Sentiment%20Analysis%20Dataset</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20llama-3.1-8b-it%20on%20Sentiment%20Analysis%20Dataset/runs/534ugfw0' target=\"_blank\">https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20llama-3.1-8b-it%20on%20Sentiment%20Analysis%20Dataset/runs/534ugfw0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import wandb\n","\n","from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","\n","wb_token = user_secrets.get_secret(\"wandb\")\n","\n","wandb.login(key=wb_token)\n","run = wandb.init(\n","    project='Fine-tune llama-3.1-8b-it on Sentiment Analysis Dataset', \n","    job_type=\"training\", \n","    anonymous=\"allow\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["# **ON CLASSIFICATION TASK**"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:28:05.425376Z","iopub.status.busy":"2024-11-11T21:28:05.425028Z","iopub.status.idle":"2024-11-11T21:28:05.998177Z","shell.execute_reply":"2024-11-11T21:28:05.997359Z","shell.execute_reply.started":"2024-11-11T21:28:05.425341Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","from tqdm import tqdm\n","import bitsandbytes as bnb\n","import torch\n","import torch.nn as nn\n","import transformers\n","from datasets import Dataset\n","from peft import LoraConfig, PeftConfig\n","from trl import SFTTrainer\n","from trl import setup_chat_format\n","from transformers import (AutoModelForCausalLM, \n","                          AutoTokenizer, \n","                          BitsAndBytesConfig, \n","                          TrainingArguments, \n","                          pipeline, \n","                          logging)\n","from sklearn.metrics import (accuracy_score, \n","                             classification_report, \n","                             confusion_matrix)\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:28:05.999903Z","iopub.status.busy":"2024-11-11T21:28:05.999274Z","iopub.status.idle":"2024-11-11T21:28:06.436757Z","shell.execute_reply":"2024-11-11T21:28:06.435495Z","shell.execute_reply.started":"2024-11-11T21:28:05.999869Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>statement</th>\n","      <th>status</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>oh my gosh</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>trouble sleeping, confused mind, restless hear...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I've shifted my focus to something else but I'...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I'm restless and restless, it's been a month n...</td>\n","      <td>Anxiety</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           statement   status\n","0                                         oh my gosh  Anxiety\n","1  trouble sleeping, confused mind, restless hear...  Anxiety\n","2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n","3  I've shifted my focus to something else but I'...  Anxiety\n","4  I'm restless and restless, it's been a month n...  Anxiety"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Loading and processing the dataset\n","df = pd.read_csv(\"/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv\",index_col = \"Unnamed: 0\")\n","df.loc[:,'status'] = df.loc[:,'status'].str.replace('Bi-Polar','Bipolar')\n","df = df[(df.status != \"Personality disorder\") & (df.status != \"Stress\") & (df.status != \"Suicidal\")]\n","df.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:28:06.444519Z","iopub.status.busy":"2024-11-11T21:28:06.444182Z","iopub.status.idle":"2024-11-11T21:28:06.513501Z","shell.execute_reply":"2024-11-11T21:28:06.512608Z","shell.execute_reply.started":"2024-11-11T21:28:06.444483Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_225/550093254.py:31: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X_train.loc[:,'text'] = X_train.apply(generate_prompt, axis=1)\n","/tmp/ipykernel_225/550093254.py:32: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X_eval.loc[:,'text'] = X_eval.apply(generate_prompt, axis=1)\n"]}],"source":["# Shuffle the DataFrame and select only 3000 rows\n","df = df.sample(frac=1, random_state=85).reset_index(drop=True).head(3000)\n","\n","# Split the DataFrame\n","train_size = 0.8\n","eval_size = 0.1\n","\n","# Calculate sizes\n","train_end = int(train_size * len(df))\n","eval_end = train_end + int(eval_size * len(df))\n","\n","# Split the data\n","X_train = df[:train_end]\n","X_eval = df[train_end:eval_end]\n","X_test = df[eval_end:]\n","\n","# Define the prompt generation functions\n","def generate_prompt(data_point):\n","    return f\"\"\"\n","            Classify the text into Normal, Depression, Anxiety, Bipolar, and return the answer as the corresponding mental health disorder label.\n","text: {data_point[\"statement\"]}\n","label: {data_point[\"status\"]}\"\"\".strip()\n","\n","def generate_test_prompt(data_point):\n","    return f\"\"\"\n","            Classify the text into Normal, Depression, Anxiety, Bipolar, and return the answer as the corresponding mental health disorder label.\n","text: {data_point[\"statement\"]}\n","label: \"\"\".strip()\n","\n","# Generate prompts for training and evaluation data\n","X_train.loc[:,'text'] = X_train.apply(generate_prompt, axis=1)\n","X_eval.loc[:,'text'] = X_eval.apply(generate_prompt, axis=1)\n","\n","# Generate test prompts and extract true labels\n","y_true = X_test.loc[:,'status']\n","X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:28:06.514995Z","iopub.status.busy":"2024-11-11T21:28:06.514673Z","iopub.status.idle":"2024-11-11T21:28:06.524086Z","shell.execute_reply":"2024-11-11T21:28:06.523094Z","shell.execute_reply.started":"2024-11-11T21:28:06.514961Z"},"trusted":true},"outputs":[{"data":{"text/plain":["status\n","Normal        1028\n","Depression     938\n","Anxiety        258\n","Bipolar        176\n","Name: count, dtype: int64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["X_train.status.value_counts()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:28:06.526230Z","iopub.status.busy":"2024-11-11T21:28:06.525481Z","iopub.status.idle":"2024-11-11T21:28:06.550966Z","shell.execute_reply":"2024-11-11T21:28:06.550170Z","shell.execute_reply.started":"2024-11-11T21:28:06.526185Z"},"trusted":true},"outputs":[],"source":["# Convert to datasets\n","train_data = Dataset.from_pandas(X_train[[\"text\"]])\n","eval_data = Dataset.from_pandas(X_eval[[\"text\"]])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:28:06.552446Z","iopub.status.busy":"2024-11-11T21:28:06.552146Z","iopub.status.idle":"2024-11-11T21:28:06.564334Z","shell.execute_reply":"2024-11-11T21:28:06.563321Z","shell.execute_reply.started":"2024-11-11T21:28:06.552414Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Classify the text into Normal, Depression, Anxiety, Bipolar, and return the answer as the corresponding mental health disorder label.\\ntext: I am so sad. Everything in my work life is going fine, but my personal life is a wreck. No one ever takes me seriously because I am the funny friend. I do not want to talk to anyone anymore. I just want to die sometimes. Please help me. I have never had this feeling in my entire life. Why am I so sad\\nlabel: Depression'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train_data['text'][3]"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:28:06.566118Z","iopub.status.busy":"2024-11-11T21:28:06.565503Z","iopub.status.idle":"2024-11-11T21:28:18.159223Z","shell.execute_reply":"2024-11-11T21:28:18.158140Z","shell.execute_reply.started":"2024-11-11T21:28:06.566081Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.1)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -U bitsandbytes"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:28:18.240263Z","iopub.status.busy":"2024-11-11T21:28:18.239926Z","iopub.status.idle":"2024-11-11T21:28:25.502310Z","shell.execute_reply":"2024-11-11T21:28:25.501442Z","shell.execute_reply.started":"2024-11-11T21:28:18.240223Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"adb57e2cc40a43b3b1741a717033e124","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Loading the model and tokenizer\n","base_model_name = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=False,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=\"float16\",\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model_name,\n","    device_map=\"auto\",\n","    torch_dtype=\"float16\",\n","    quantization_config=bnb_config, \n",")\n","\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1\n","\n","tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n","\n","tokenizer.pad_token_id = tokenizer.eos_token_id"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:29:05.468946Z","iopub.status.busy":"2024-11-11T21:29:05.468543Z","iopub.status.idle":"2024-11-11T21:30:00.721495Z","shell.execute_reply":"2024-11-11T21:30:00.720579Z","shell.execute_reply.started":"2024-11-11T21:29:05.468907Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 300/300 [00:55<00:00,  5.43it/s]\n"]}],"source":["# evaluation\n","def predict(test, model, tokenizer):\n","    y_pred = []\n","    categories = [\"Normal\", \"Depression\", \"Anxiety\", \"Bipolar\"]\n","    \n","    for i in tqdm(range(len(test))):\n","        prompt = test.iloc[i][\"text\"]\n","        pipe = pipeline(task=\"text-generation\", \n","                        model=model, \n","                        tokenizer=tokenizer, \n","                        max_new_tokens=2, \n","                        temperature=0.1)\n","        \n","        result = pipe(prompt)\n","        answer = result[0]['generated_text'].split(\"label:\")[-1].strip()\n","        \n","        # Determine the predicted category\n","        for category in categories:\n","            if category.lower() in answer.lower():\n","                y_pred.append(category)\n","                break\n","        else:\n","            y_pred.append(\"none\")\n","    \n","    return y_pred\n","\n","y_pred = predict(X_test, model, tokenizer)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:31:26.457254Z","iopub.status.busy":"2024-11-11T21:31:26.456833Z","iopub.status.idle":"2024-11-11T21:31:26.488288Z","shell.execute_reply":"2024-11-11T21:31:26.487243Z","shell.execute_reply.started":"2024-11-11T21:31:26.457215Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" ###### R E S U L T S     W I T H O U T     F I N E T U N I N G ######\n","Accuracy: 0.677\n","Accuracy for label Normal: 1.000\n","Accuracy for label Depression: 0.522\n","Accuracy for label Anxiety: 0.000\n","Accuracy for label Bipolar: 0.000\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      Normal       0.63      1.00      0.78       143\n","  Depression       0.90      0.52      0.66       115\n","     Anxiety       0.00      0.00      0.00        27\n","     Bipolar       0.00      0.00      0.00        15\n","\n","   micro avg       0.69      0.68      0.68       300\n","   macro avg       0.38      0.38      0.36       300\n","weighted avg       0.64      0.68      0.62       300\n","\n","\n","Confusion Matrix:\n","[[143   0   0   0]\n"," [ 52  60   1   0]\n"," [ 21   4   0   0]\n"," [ 10   3   0   0]]\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["def evaluate(y_true, y_pred):\n","    labels = [\"Normal\", \"Depression\", \"Anxiety\", \"Bipolar\"]\n","    mapping = {label: idx for idx, label in enumerate(labels)}\n","    \n","    def map_func(x):\n","        return mapping.get(x, -1)  # Map to -1 if not found, but should not occur with correct data\n","    \n","    y_true_mapped = np.vectorize(map_func)(y_true)\n","    y_pred_mapped = np.vectorize(map_func)(y_pred)\n","    \n","    # Calculate accuracy\n","    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n","    print(f'Accuracy: {accuracy:.3f}')\n","    \n","    # Generate accuracy report\n","    unique_labels = set(y_true_mapped)  # Get unique labels\n","    \n","    for label in unique_labels:\n","        label_indices = [i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label]\n","        label_y_true = [y_true_mapped[i] for i in label_indices]\n","        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n","        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n","        print(f'Accuracy for label {labels[label]}: {label_accuracy:.3f}')\n","        \n","    # Generate classification report\n","    class_report = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=labels, labels=list(range(len(labels))))\n","    print('\\nClassification Report:')\n","    print(class_report)\n","    \n","    # Generate confusion matrix\n","    conf_matrix = confusion_matrix(y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(labels))))\n","    print('\\nConfusion Matrix:')\n","    print(conf_matrix)\n","\n","print(\" ###### R E S U L T S     W I T H O U T     F I N E T U N I N G ######\")\n","evaluate(y_true, y_pred)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:32:02.006395Z","iopub.status.busy":"2024-11-11T21:32:02.005991Z","iopub.status.idle":"2024-11-11T21:32:02.017667Z","shell.execute_reply":"2024-11-11T21:32:02.016754Z","shell.execute_reply.started":"2024-11-11T21:32:02.006360Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['v_proj', 'gate_proj', 'o_proj', 'down_proj', 'up_proj', 'k_proj', 'q_proj']"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["import bitsandbytes as bnb\n","# MODEL building\n","def find_all_linear_names(model):\n","    cls = bnb.nn.Linear4bit\n","    lora_module_names = set()\n","    for name, module in model.named_modules():\n","        if isinstance(module, cls):\n","            names = name.split('.')\n","            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n","    if 'lm_head' in lora_module_names:  # needed for 16 bit\n","        lora_module_names.remove('lm_head')\n","    return list(lora_module_names)\n","modules = find_all_linear_names(model)\n","modules"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:32:35.800020Z","iopub.status.busy":"2024-11-11T21:32:35.799614Z","iopub.status.idle":"2024-11-11T21:32:38.237309Z","shell.execute_reply":"2024-11-11T21:32:38.236523Z","shell.execute_reply.started":"2024-11-11T21:32:35.799976Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, dataset_kwargs. Will not be supported from version '0.13.0'.\n","\n","Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n","  warnings.warn(message, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:334: UserWarning: You passed a `dataset_kwargs` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec52451913484faf82eeae8bfa3abe9d","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2400 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c5c0e7ee2924acaae24d00cb24d2d8d","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/300 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["output_dir=\"llama-3.2-fine-tuned-model\"\n","\n","peft_config = LoraConfig(\n","    lora_alpha=16,\n","    lora_dropout=0,\n","    r=64,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=modules,\n",")\n","\n","training_arguments = TrainingArguments(\n","    output_dir=output_dir,                    # directory to save and repository id\n","    num_train_epochs=1,                       # number of training epochs\n","    per_device_train_batch_size=1,            # batch size per device during training\n","    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n","    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n","    optim=\"paged_adamw_32bit\",\n","    logging_steps=1,                         \n","    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n","    weight_decay=0.001,\n","    fp16=True,\n","    bf16=False,\n","    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n","    max_steps=-1,\n","    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n","    group_by_length=False,\n","    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n","    report_to=\"wandb\",                  # report metrics to w&b\n","    eval_strategy=\"steps\",              # save checkpoint every epoch\n","    eval_steps = 0.2\n",")\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    args=training_arguments,\n","    train_dataset=train_data,\n","    eval_dataset=eval_data,\n","    peft_config=peft_config,\n","    dataset_text_field=\"text\",\n","    tokenizer=tokenizer,\n","    max_seq_length=512,\n","    packing=False,\n","    dataset_kwargs={\n","    \"add_special_tokens\": False,\n","    \"append_concat_token\": False,\n","    }\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T21:33:58.489165Z","iopub.status.busy":"2024-11-11T21:33:58.488493Z","iopub.status.idle":"2024-11-11T22:00:48.359009Z","shell.execute_reply":"2024-11-11T22:00:48.358085Z","shell.execute_reply.started":"2024-11-11T21:33:58.489113Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 26:44, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>60</td>\n","      <td>1.980800</td>\n","      <td>2.304704</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>2.271800</td>\n","      <td>2.278444</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>1.879800</td>\n","      <td>2.264527</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>2.152000</td>\n","      <td>2.256824</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>2.316500</td>\n","      <td>2.254664</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=300, training_loss=2.3382046286265057, metrics={'train_runtime': 1609.4552, 'train_samples_per_second': 1.491, 'train_steps_per_second': 0.186, 'total_flos': 5725431561080832.0, 'train_loss': 2.3382046286265057, 'epoch': 1.0})"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:00:51.796016Z","iopub.status.busy":"2024-11-11T22:00:51.795613Z","iopub.status.idle":"2024-11-11T22:00:53.302289Z","shell.execute_reply":"2024-11-11T22:00:53.301401Z","shell.execute_reply.started":"2024-11-11T22:00:51.795976Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"285433245e7343c6a4a83a105549152a","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.035 MB of 0.035 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/runtime</td><td>█▃▁▆▆</td></tr><tr><td>eval/samples_per_second</td><td>▁▆█▃▃</td></tr><tr><td>eval/steps_per_second</td><td>▁██▅▅</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▅▂█▂▁▂▁▁▁▂▂▁▂▁▂▁▂▂▂▂▃▁▃▂▃▂▃▂▂▁▂▃▁▂▁▁▂▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▃▇███████████▇▇▇▆▆▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▂▄▄▃▃▃▃▂▄▅▃▃▃▃▃▃▃▃▃▂▂▂▃▃▃▂▃▃▃▄▃▃▃▁▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.25466</td></tr><tr><td>eval/runtime</td><td>57.0658</td></tr><tr><td>eval/samples_per_second</td><td>5.257</td></tr><tr><td>eval/steps_per_second</td><td>0.666</td></tr><tr><td>total_flos</td><td>5725431561080832.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>300</td></tr><tr><td>train/grad_norm</td><td>0.21386</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>2.3165</td></tr><tr><td>train_loss</td><td>2.3382</td></tr><tr><td>train_runtime</td><td>1609.4552</td></tr><tr><td>train_samples_per_second</td><td>1.491</td></tr><tr><td>train_steps_per_second</td><td>0.186</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">light-pine-2</strong> at: <a href='https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20llama-3.1-8b-it%20on%20Sentiment%20Analysis%20Dataset/runs/534ugfw0' target=\"_blank\">https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20llama-3.1-8b-it%20on%20Sentiment%20Analysis%20Dataset/runs/534ugfw0</a><br/> View project at: <a href='https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20llama-3.1-8b-it%20on%20Sentiment%20Analysis%20Dataset' target=\"_blank\">https://wandb.ai/rakibulislamprince10-purdue-university/Fine-tune%20llama-3.1-8b-it%20on%20Sentiment%20Analysis%20Dataset</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241111_212802-534ugfw0/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()\n","model.config.use_cache = True"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:00:57.755436Z","iopub.status.busy":"2024-11-11T22:00:57.754534Z","iopub.status.idle":"2024-11-11T22:00:58.778268Z","shell.execute_reply":"2024-11-11T22:00:58.777118Z","shell.execute_reply.started":"2024-11-11T22:00:57.755379Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('llama-3.2-fine-tuned-model/tokenizer_config.json',\n"," 'llama-3.2-fine-tuned-model/special_tokens_map.json',\n"," 'llama-3.2-fine-tuned-model/tokenizer.json')"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Save trained model and tokenizer\n","trainer.save_model(output_dir)\n","tokenizer.save_pretrained(output_dir)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-11-11T22:07:07.925880Z","iopub.status.busy":"2024-11-11T22:07:07.924921Z","iopub.status.idle":"2024-11-11T22:08:33.371561Z","shell.execute_reply":"2024-11-11T22:08:33.370589Z","shell.execute_reply.started":"2024-11-11T22:07:07.925832Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 300/300 [01:25<00:00,  3.51it/s]"]},{"name":"stdout","output_type":"stream","text":[" ###### R E S U L T S     A F T E R     F I N E T U N I N G ######\n","Accuracy: 0.903\n","Accuracy for label Normal: 0.979\n","Accuracy for label Depression: 0.878\n","Accuracy for label Anxiety: 0.630\n","Accuracy for label Bipolar: 0.867\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      Normal       0.90      0.98      0.94       143\n","  Depression       0.95      0.88      0.91       115\n","     Anxiety       0.89      0.63      0.74        27\n","     Bipolar       0.72      0.87      0.79        15\n","\n","   micro avg       0.91      0.90      0.90       300\n","   macro avg       0.87      0.84      0.84       300\n","weighted avg       0.91      0.90      0.90       300\n","\n","\n","Confusion Matrix:\n","[[140   2   0   1]\n"," [  8 101   2   3]\n"," [  7   2  17   1]\n"," [  1   1   0  13]]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["y_pred = predict(X_test, model, tokenizer)\n","print(\" ###### R E S U L T S     A F T E R     F I N E T U N I N G ######\")\n","evaluate(y_true, y_pred)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5338273,"sourceId":8870083,"sourceType":"datasetVersion"},{"modelId":121027,"modelInstanceId":97843,"sourceId":116428,"sourceType":"modelInstanceVersion"},{"modelId":121027,"modelInstanceId":100936,"sourceId":120005,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
